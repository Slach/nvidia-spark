[noctrex/MiniMax-M2-139B]
model = ~/.cache/huggingface/hub/models--noctrex--MiniMax-M2-REAP-139B-A10B-MXFP4_MOE-GGUF/snapshots/cc06d93e4cb80d0675be2305dcdb545d1e42d6cc/MiniMax-M2-REAP-139B-A10B-MXFP4_MOE-00001-of-00005.gguf
# unfortunatelly it doesn't fit to 128G RAM for 192k context ;( 
# ctx-size = 196608
ctx-size = 167936


[noctrex/Qwen3-Next-80B]
model = ~/.cache/huggingface/hub/models--noctrex--Qwen3-Next-80B-A3B-Instruct-1M-MXFP4_MOE-GGUF/snapshots/4c791a92568d68271a1f38403b7932a518631787/ Qwen3-Next-80B-A3B-Instruct-1M-MXFP4_MOE-00001-of-00003.gguf
ctx-size = 0
rope-scaling = yarn 
rope-scale = 4

# [noctrex/Nemotron-3-Nano-30B]
# model = ~/.cache/huggingface/hub/models--noctrex--Qwen3-Next-80B-A3B-Instruct-1M-MXFP4_MOE-GGUF/snapshots/4c791a92568d68271a1f38403b7932a518631787/ Qwen3-Next-80B-A3B-Instruct-1M-MXFP4_MOE-00001-of-00003.gguf
# ctx-size = 0
