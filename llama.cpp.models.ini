[noctrex/MiniMax-M2-139B]
model = /models/huggingface/hub/models--noctrex--MiniMax-M2-REAP-139B-A10B-MXFP4_MOE-GGUF/snapshots/cc06d93e4cb80d0675be2305dcdb545d1e42d6cc/MiniMax-M2-REAP-139B-A10B-MXFP4_MOE-00001-of-00005.gguf
# unfortunatelly it doesn't fit to 128G RAM for 192k context ;( 
# ctx-size = 196608
ctx-size = 167936

[noctrex/Qwen3-Next-80B]
model = /models/huggingface/hub/models--noctrex--Qwen3-Next-80B-A3B-Instruct-1M-MXFP4_MOE-GGUF/snapshots/4c791a92568d68271a1f38403b7932a518631787/Qwen3-Next-80B-A3B-Instruct-1M-MXFP4_MOE-00001-of-00003.gguf
ctx-size = 1048576
rope-scaling = yarn 
rope-scale = 4

[noctrex/Nemotron-3-Nano-30B]
model = /models/huggingface/hub/models--noctrex--Nemotron-3-Nano-30B-A3B-MXFP4_MOE-GGUF/snapshots/175835a96514b1c3c12a5f4b842c829d26dba202/NVIDIA-Nemotron-3-Nano-30B-A3B-MXFP4_MOE.gguf

# too slow, but works
# [unsloth/Devstral-2-123B-Instruct-2512-GGUF]
# model = /models/huggingface/hub/models--unsloth--Devstral-2-123B-Instruct-2512-GGUF/snapshots/1f2bfbe35f7f9071d9b318374bf5eeffefab4459/UD-Q4_K_XL/Devstral-2-123B-Instruct-2512-UD-Q4_K_XL-00001-of-00002.gguf

[bartowski/zai-org_GLM-4.7]
model = /models/huggingface/hub/models--bartowski--zai-org_GLM-4.7-GGUF/snapshots/c47ba4573051e4a5146879669a8a95743b5302a4/zai-org_GLM-4.7-IQ1_M/zai-org_GLM-4.7-IQ1_M-00001-of-00003.gguf

[unsloth/GLM-4.7-Flash-30B]
model = /models/huggingface/hub/models--unsloth--GLM-4.7-Flash-GGUF/snapshots/66205ea11ef638d83850389bd921e6c199f7504e/GLM-4.7-Flash-Q8_0.gguf
temp = 0.7 
top-p = 1.0
min-p = 0.01
 
[endyjasmi/Qwen3-Embedding-8B]
model = /models/huggingface/hub/models--endyjasmi--Qwen3-Embedding-8B-Q4_K_M-GGUF/snapshots/b74bf2a75d37d23867612c1b81655e4496535086/qwen3-embedding-8b-q4_k_m.gguf

# stupid
# [cturan/IQuest-Coder-V1-40B]
# model = /models/huggingface/hub/models--cturan--IQuest-Coder-V1-40B-Instruct-GGUF/snapshots/c520c173b24f57d25e6431598cd2b3d2c4c8748e/IQuest-Coder-V1-40B-Instruct.Q4_K_M.gguf

[tiiuae/Falcon-H1R-7B]
model = /models/huggingface/hub/models--tiiuae--Falcon-H1R-7B-GGUF/snapshots/21539e5e8334bfd5474da7fffd0f82d0a97c6d0e/Falcon-H1R-7B-Q8_0.gguf

# too stupid
# [noctrex/HyperNova-60B]
# model = /models/huggingface/hub/models--noctrex--HyperNova-60B-MXFP4_MOE-GGUF/snapshots/81f93ea3f69d38c89c8e032766573b5962185a73/HyperNova-60B-MXFP4_MOE.gguf 


