[noctrex/MiniMax-M2-139B]
model = /models/huggingface/hub/models--noctrex--MiniMax-M2-REAP-139B-A10B-MXFP4_MOE-GGUF/snapshots/cc06d93e4cb80d0675be2305dcdb545d1e42d6cc/MiniMax-M2-REAP-139B-A10B-MXFP4_MOE-00001-of-00005.gguf
# unfortunatelly it doesn't fit to 128G RAM for 192k context ;( 
# ctx-size = 196608
ctx-size = 167936


[noctrex/Qwen3-Next-80B]
model = /models/huggingface/hub/models--noctrex--Qwen3-Next-80B-A3B-Instruct-1M-MXFP4_MOE-GGUF/snapshots/4c791a92568d68271a1f38403b7932a518631787/Qwen3-Next-80B-A3B-Instruct-1M-MXFP4_MOE-00001-of-00003.gguf
ctx-size = 1048576
rope-scaling = yarn 
rope-scale = 4

[noctrex/Nemotron-3-Nano-30B]
model = /models/huggingface/hub/models--noctrex--Nemotron-3-Nano-30B-A3B-MXFP4_MOE-GGUF/snapshots/175835a96514b1c3c12a5f4b842c829d26dba202/NVIDIA-Nemotron-3-Nano-30B-A3B-MXFP4_MOE.gguf

[endyjasmi/Qwen3-Embedding-8B]
model = /models/huggingface/hub/models--endyjasmi--Qwen3-Embedding-8B-Q4_K_M-GGUF/snapshots/b74bf2a75d37d23867612c1b81655e4496535086/qwen3-embedding-8b-q4_k_m.gguf

